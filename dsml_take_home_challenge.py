# -*- coding: utf-8 -*-
"""Copy of DSML_Take-Home_Challenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WRk-f-_Yarxk0toLCyhaThC95cHs8dkS

# Codesmith Take Home Challenge

For this take home challenge you will be using foundational data science python libraries to analyze a dataset related to diabetes patients and develop a basic logistic regression model.

The libraries we will be using are:
 - [Pandas](https://pandas.pydata.org/)
 - [Sklearn](https://scikit-learn.org/stable/)
 - [Matplotlib](https://www.w3schools.com/python/matplotlib_pyplot.asp)

The data is collected from the Behavioral Risk Factor Surveillance System (BRFSS) dataset and provided by [Kaggle](https://www.kaggle.com/competitions/diabetes-prediction-competitiontfug-chd-nov-2022/data). You can view the raw data [here](https://raw.githubusercontent.com/CodesmithLLC/dsml-datasets/main/train_dataset.csv).

Submit your answers to the prompts [here](https://forms.gle/66VdMARikw7BAYs97)

## Getting Started
- Make a copy of this notebook and name `DSML_Admissions_{Your Initials}.py` (File -> Save a Copy in Drive)
- Complete the challenges below. Answer each question in a separate cell.
- Submit your answers questions in the take home form.

## Challenge 1
Use the pandas library to explore the provided dataset and answer the questions in the Google Form.

## Do's and Don'ts

Only use Pandas to gather information about this dataset. Do not load the data file with an external program like Excel or Google Sheet.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !python3 -m pip install --upgrade pip setuptools wheel request
# !pip3 install pandas sklearn matplotlib numpy

import pandas as pd

train_dataset = pd.read_csv('https://raw.githubusercontent.com/CodesmithLLC/dsml-datasets/main/train_dataset.csv')
train_dataset

# write pandas code here to answer Part 1 questions
import pandas as pd
url = 'https://raw.githubusercontent.com/CodesmithLLC/dsml-datasets/main/train_dataset.csv'
train_dataset = pd.read_csv(url)
train_dataset.describe()
# Total number of rows and colums in the dataset
num_rows, num_columns = train_dataset.shape
print("Total number of rows:", num_rows)
print("Total number of columns:", num_columns)

#Basic statistics of the numeric columns in the dataset
summary_stats = train_dataset.describe()
print(summary_stats)

#Number of unique values in each column
unique_values = train_dataset.nunique()
print("Number of unique values in each column:")
print(unique_values)

# Frequency count of the 'Sex' column
sex_counts = train_dataset['Sex'].value_counts()
print("Frequency count of 'Sex' column:")
print(sex_counts)

"""## Challenge 2

Now that we have some familiarity with this dataset, we'll train a simple [logistic regression](https://www.youtube.com/watch?v=yIYKR4sgzI8) model using the Scikit-learn library. Your main task is to generate evaluation metrics to assess the model's performance, while the code for training the logistic model has been provided for you.
"""

from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, roc_auc_score

model = LogisticRegression()

test_dataset = pd.read_csv('https://raw.githubusercontent.com/CodesmithLLC/dsml-datasets/main/test_dataset.csv')

train_X = train_dataset[['BMI', 'GenHlth', 'Age']]
train_Y = train_dataset[['Diabetes']].values.reshape(-1)

model.fit(train_X, train_Y)

# write code here to answer questions for Part 2
import pandas as pd
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score

url_train = 'https://raw.githubusercontent.com/CodesmithLLC/dsml-datasets/main/train_dataset.csv'
train_dataset = pd.read_csv(url_train)


url_test = 'https://raw.githubusercontent.com/CodesmithLLC/dsml-datasets/main/test_dataset.csv'
test_dataset = pd.read_csv(url_test)

test_X = test_dataset[['BMI', 'GenHlth', 'Age']]
test_Y = test_dataset['Diabetes']

#Logistic regression model
model = LogisticRegression()
#Train model using fit() method on the training data
model.fit(train_X, train_Y)

#Train the model using the fit() moethod on the training data
train_X = train_dataset[['BMI', 'GenHlth', 'Age']]
train_Y = train_dataset[['Diabetes']].values.reshape(-1)



#Make predictions on the test set
y_pred = model.predict(test_X)

#Compute confusion matrix
conf_matrix = confusion_matrix(test_Y, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

# Calculate the predicted probabilities for the positive class
y_prob = model.predict_proba(test_X)[:, 1]

# Calculate the false positive rate, true positive rate
fpr, tpr, thresholds = roc_curve(test_Y, y_prob)

# Calculate AUC score
auc_score = roc_auc_score(test_Y, y_prob)

# Plot the ROC curve
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label= f'ROC Curve (AUC = {auc_score:.2f})')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

print("AUC Score:", auc_score)

"""## Challenge 3

Solve the following question just using python:

- Total number of words. Strings like `a.k.a` and `e.g.` should be considered a single word
- Total number of unique words. `"spam"` and `spam` should be considered the same word
- What is the most frequent word that appears in the below text (case insenstive)? Exclude stop words (e.g `and`, `or`, `the`). A list of stop words have been provided.

## Do's and Don'ts

Do not download (`pip install`) any external libs to solve this problem. Just use python and any built-in modules you may need.
"""

# source: https://sites.astro.caltech.edu/~george/ay122/cacm12.pdf
TEXT = '''
Machine learning systems automatically learn programs from
data. This is often a very attractive alternative to manually
constructing them, and in the last decade the use of machine
learning has spread rapidly throughout computer science
and beyond. Machine learning is used in Web search, spam
filters, recommender systems, ad placement, credit scoring,
fraud detection, stock trading, drug design, and many other
applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or
predictive analytics) will be the driver of the next big wave of
innovation [15]. Several fine textbooks are available to interested practitioners and researchers (e.g, [16, 24]). However,
much of the “folk knowledge” that is needed to successfully
develop machine learning applications is not readily available in them. As a result, many machine learning projects
take much longer than necessary or wind up producing lessthan-ideal results. Yet much of this folk knowledge is fairly
easy to communicate. This is the purpose of this article.
Many different types of machine learning exist, but for illustration purposes I will focus on the most mature and
widely used one: classification. Nevertheless, the issues I
will discuss apply across all of machine learning. A classifier is a system that inputs (typically) a vector of discrete
and/or continuous feature values and outputs a single discrete value, the class. For example, a spam filter classifies
email messages into “spam” or “not spam,” and its input may
be a Boolean vector x = (x1, . . . , xj , . . . , xd), where xj = 1
if the jth word in the dictionary appears in the email and
xj = 0 otherwise. A learner inputs a training set of examples (xi, yi), where xi = (xi,1, . . . , xi,d) is an observed input
and yi is the corresponding output, and outputs a classifier.
The test of the learner is whether this classifier produces the
correct output yt for future examples xt (e.g., whether the
spam filter correctly classifies previously unseen emails as
spam or not spam).
'''

STOP_WORDS = ['a', 'an', 'the', 'in', 'on', 'at', 'for', 'is', 'it', 'and', 'or', 'but', 'with', 'of', 'to']

# Write your code here
#
text = """ sample text used for testing. A.k.a, e.g., and etc.
should be considered single words. We count the total
number of words and find the most frequent word excluding stop words
like and, or, the.  """

# List of stop words
stop_words = ["and", "or", "the"]

# Count the total number of words
words_list = text.split()
total_words = len(words_list)

# Count the total number of unique word without case sensitivity
unique_words = set(word.lower() for word in words_list)

# Find the most frequent word excluding stop words
word_freq = {}
for word in words_list:
    word = word.lower()
    if word not in stop_words:
      word_freq[word] = word_freq.get(word, 0) + 1

most_frequent_word = max(word_freq, key=word_freq.get)

#Results
print("Total number of words:", total_words)
print("Total number of unique words:", len(unique_words))
print("Most frequent word (excluding stop words):", most_frequent_word)

"""## Challenge 4

Solve the following question using numpy

"""

import numpy as np

# Write a function called find_closest_vector that takes a vector and a list of vectors (i.e. a matrix) as input arguments,
# and returns the row of the matrix that is closest to the input vector (in terms of Euclidean distance).
# You can use the function np.linalg.norm to compute the Euclidean distance between two vectors.
# Example: find_closest_vector(np.array([1, 2]), np.array([[1, 1], [3, 4]])) should return np.array([1, 1]).
# Example: find_closest_vector(np.array([1, 2, 3]), np.array([[1, 1, 1], [3, 4, 5], [2, 2, 2]])) should return np.array([2, 2, 2]).
def find_closest_vector(x, vectors):
    # write code here
    # Calculate the Euclidean distance between x and each row of vectors
    distances = np.linalg.norm(vectors - x, axis=1)

    #Find the index of the row with the minimum distance
    closest_index = np.argmin(distances)

    # Return the losest vector
    return vectors[closest_index]

 #Test function with the given examples

assert (find_closest_vector(np.array([1, 2]), np.array([[1, 1], [3, 4]])) == np.array([1, 1])).all()
assert (find_closest_vector(np.array([1, 2, 3]), np.array([[1, 1, 1], [3, 4, 5], [2, 2, 2]])) == np.array([2, 2, 2])).all()
print('All tests have passed!')